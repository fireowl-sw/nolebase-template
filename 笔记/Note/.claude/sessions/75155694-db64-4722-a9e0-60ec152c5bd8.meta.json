{
  "id": "75155694-db64-4722-a9e0-60ec152c5bd8",
  "title": "Extract CS285 video course titles",
  "titleGenerationStatus": "success",
  "createdAt": 1768565825712,
  "updatedAt": 1768637974317,
  "lastResponseAt": 1768565825713,
  "sessionId": "75155694-db64-4722-a9e0-60ec152c5bd8",
  "sdkSessionId": "75155694-db64-4722-a9e0-60ec152c5bd8",
  "usage": {
    "model": "glm-4.7",
    "inputTokens": 23103,
    "cacheCreationInputTokens": 0,
    "cacheReadInputTokens": 42368,
    "contextWindow": 200000,
    "contextTokens": 65471,
    "percentage": 33
  },
  "toolDiffData": {
    "call_6f1560bcab344084871995e8": {
      "filePath": "Inbox/学习路线.md",
      "originalContent": "# 具身智能学习路线 - 课程学习顺序\n\n> 2025年具身智能方向的头部公司薪资已能与大厂LLM岗位相媲美，以下为个人找工学习路线（VLA方向）\n\n---\n\n## 一、基础知识学习顺序\n\n### 1. 机器人学基础\n- **内容**：机器人正逆运动学、相机标定知识\n- **学习方式**：B站机器人学课程 - 运动学章节\n- **实践**：机械臂实践课、基于旋量的运动学和动力学课程\n\n### 2. 生成模型基础\n- **内容**：Diffusion Model、Flow Matching\n- **推荐课程**：MIT 6.S184（强烈推荐）\n- **学习方式**：\n  - 先阅读论文\n  - 完成课程全部作业\n  - 深入理解Flow Matching\n\n### 3. 强化学习基础\n- **推荐课程**：Berkeley CS285\n- **学习时间**：约2个月\n- **学习要求**：\n  - **必须完成作业**\n  - 反复听不懂的地方\n  - 融会贯通\n- **备注**：课程中也包含Act讲解（VAE部分）\n\n### 4. 模仿学习基础\n- **内容**：Act、Diffusion Policy\n- **学习方式**：阅读论文\n- **关联课程**：CS285课程中会有Act讲解\n\n### 5. 大模型基础\n- **推荐课程**：CS336\n- **实践要求**：从头手搓一个大模型\n\n---\n\n## 二、VLA实战学习顺序\n\n### 第一阶段：了解VLA\n- 学习OpenVLA等早期VLA模型\n- 理解VLA的核心概念和工作原理\n\n### 第二阶段：深入研究\n- **精读pi系列所有论文与代码**：\n  - pi0\n  - pi0.5\n  - RTC\n  - 其他相关文章\n\n### 第三阶段：实践操作\n- 跑仿真环境\n- 实际操作\n- **达到要求后**：可以找实习或启动研究工作\n\n---\n\n## 三、研究方向选择\n\n### 推荐方向\n\n| 方向 | 热度 | 说明 |\n|------|------|------|\n| **Tactile + VLA** | ⭐⭐⭐⭐⭐ | 主包方向，靠此拿了很多offer |\n| **VLA + RL** | ⭐⭐⭐⭐⭐ | 企业主流方向，完美契合公司需求 |\n| **3D VLA** | ⭐⭐⭐⭐ | 许多公司在做，很有前景 |\n| **World Model** | ⭐⭐⭐ | VLA可能不可行，但WM有研究价值 |\n\n---\n\n## 四、学习时间线（参考）\n\n```\n2025.1  - 2025.5  │ 基础学习（强化学习、生成模型、大模型）\n2025.5  - 2025.9  │ 做项目 / 研究\n2025.9  - 2025.10 │ 面试\n```\n\n---\n\n## 关键要点\n\n1. ✅ **CS285必须完成作业** - 光看视频不够\n2. ✅ **MIT 6.S184强烈推荐** - 完成作业后对flow matching理解清晰很多\n3. ✅ **精读pi系列** - 这是VLA实战的核心\n4. ✅ **动手实践** - 仿真+实操缺一不可\n5. ✅ **选择热门研究方向** - Tactile+VLA 或 VLA+RL\n",
      "newContent": "# 具身智能学习路线 - 课程学习顺序\n\n> 2025年具身智能方向的头部公司薪资已能与大厂LLM岗位相媲美，以下为个人找工学习路线（VLA方向）\n\n---\n\n## 一、基础知识学习顺序\n\n### 1. 机器人学基础\n- **内容**：机器人正逆运动学、相机标定知识\n- **学习方式**：B站机器人学课程 - 运动学章节\n- **实践**：机械臂实践课、基于旋量的运动学和动力学课程\n\n### 2. 生成模型基础\n- **内容**：Diffusion Model、Flow Matching\n- **推荐课程**：MIT 6.S184（强烈推荐）\n- **学习方式**：\n  - 先阅读论文\n  - 完成课程全部作业\n  - 深入理解Flow Matching\n\n### 3. 强化学习基础\n- **推荐课程**：Berkeley CS285\n- **学习时间**：约2个月\n- **学习要求**：\n  - **必须完成作业**\n  - 反复听不懂的地方\n  - 融会贯通\n- **备注**：课程中也包含Act讲解（VAE部分）\n\n#### 课程视频列表\n\n**Lecture 1: Introduction**\n- CS 285: Lecture 1, Introduction. Part 1 (10:11)\n- CS 285: Lecture 1, Introduction. Part 2 (17:55)\n- CS 285: Lecture 1, Introduction. Part 3 (29:02)\n\n**Lecture 2: Imitation Learning**\n- CS 285: Lecture 2, Imitation Learning. Part 1 (24:48)\n- CS 285: Lecture 2, Imitation Learning. Part 2 (23:07)\n- CS 285: Lecture 2, Imitation Learning. Part 3 (32:23)\n- CS 285: Lecture 2, Imitation Learning. Part 4 (08:32)\n- CS 285: Lecture 2, Imitation Learning. Part 5 (08:52)\n\n**Lecture 4**\n- CS 285: Lecture 4, Part 1 (26:29)\n- CS 285: Lecture 4, Part 2 (07:24)\n- CS 285: Lecture 4, Part 3 (09:11)\n- CS 285: Lecture 4, Part 4 (05:51)\n- CS 285: Lecture 4, Part 5 (09:15)\n- CS 285: Lecture 4, Part 6 (03:04)\n\n**Lecture 5**\n- CS 285: Lecture 5, Part 1 (14:02)\n- CS 285: Lecture 5, Part 2 (13:17)\n- CS 285: Lecture 5, Part 3 (14:52)\n- CS 285: Lecture 5, Part 4 (15:41)\n- CS 285: Lecture 5, Part 5 (07:33)\n- CS 285: Lecture 5, Part 6 (13:32)\n\n**Lecture 6**\n- CS 285: Lecture 6, Part 1 (25:13)\n- CS 285: Lecture 6, Part 2 (17:29)\n- CS 285: Lecture 6, Part 3 (18:32)\n- CS 285: Lecture 6, Part 4 (15:55)\n- CS 285: Lecture 6, Part 5 (03:36)\n\n**Lecture 7**\n- CS 285: Lecture 7, Part 1 (16:17)\n- CS 285: Lecture 7, Part 2 (15:08)\n- CS 285: Lecture 7, Part 3 (11:57)\n- CS 285: Lecture 7, Part 4 (17:02)\n\n**Lecture 8**\n- CS 285: Lecture 8, Part 1 (13:38)\n- CS 285: Lecture 8, Part 2 (11:57)\n- CS 285: Lecture 8, Part 3 (08:35)\n- CS 285: Lecture 8, Part 4 (23:42)\n- CS 285: Lecture 8, Part 5 (10:05)\n- CS 285: Lecture 8, Part 6 (11:00)\n\n**Lecture 9**\n- CS 285: Lecture 9, Part 1 (21:23)\n- CS 285: Lecture 9, Part 2 (18:49)\n- CS 285: Lecture 9, Part 3 (05:50)\n- CS 285: Lecture 9, Part 4 (21:08)\n\n**Lecture 10**\n- CS 285: Lecture 10, Part 1 (19:20)\n- CS 285: Lecture 10, Part 2 (23:12)\n- CS 285: Lecture 10, Part 3 (23:49)\n- CS 285: Lecture 10, Part 4 (13:23)\n- CS 285: Lecture 10, Part 5 (06:21)\n\n**Lecture 11**\n- CS 285: Lecture 11, Part 1 (17:47)\n- CS 285: Lecture 11, Part 2 (09:35)\n- CS 285: Lecture 11, Part 3 (17:09)\n- CS 285: Lecture 11, Part 4 (06:54)\n- CS 285: Lecture 11, Part 5 (17:22)\n\n**Lecture 12: Model-Based RL with Policies**\n- CS 285: Lecture 12, Part 1: Model-Based RL with Policies (15:06)\n- CS 285: Lecture 12, Part 2: Model-Based RL with Policies (15:04)\n- CS 285: Lecture 12, Part 3: Model-Based RL with Policies (12:53)\n- CS 285: Lecture 12, Part 4: Model-Based RL with Policies (29:20)\n\n**Lecture 13**\n- CS 285: Lecture 13, Part 1 (19:52)\n- CS 285: Lecture 13, Part 2 (15:49)\n- CS 285: Lecture 13, Part 3 (14:31)\n- CS 285: Lecture 13, Part 4 (13:02)\n- CS 285: Lecture 13, Part 5 (06:50)\n- CS 285: Lecture 13, Part 6 (12:40)\n\n**Lecture 14**\n- CS 285: Lecture 14, Part 1 (14:18)\n- CS 285: Lecture 14, Part 2 (15:28)\n- CS 285: Lecture 14, Part 3 (13:53)\n- CS 285: Lecture 14, Part 4 (08:02)\n\n**Lecture 15: Offline Reinforcement Learning**\n- CS 285: Lecture 15, Part 1: Offline Reinforcement Learning (38:01)\n- CS 285: Lecture 15, Part 2: Offline Reinforcement Learning (25:33)\n- CS 285: Lecture 15, Part 3: Offline Reinforcement Learning (21:20)\n\n**Lecture 16: Offline Reinforcement Learning 2**\n- CS 285: Lecture 16, Part 1: Offline Reinforcement Learning 2 (31:59)\n- CS 285: Lecture 16, Part 2: Offline Reinforcement Learning 2 (07:33)\n- CS 285: Lecture 16, Part 3: Offline Reinforcement Learning 2 (18:17)\n- CS 285: Lecture 16, Part 4: Offline Reinforcement Learning 2 (12:20)\n\n**Lecture 17: RL Theory**\n- CS 285: Lecture 17, Part 1: RL Theory (50:10)\n- CS 285: Lecture 17, Part 2: RL Theory (21:59)\n\n**Lecture 18: Variational Inference**\n- CS 285: Lecture 18, Variational Inference, Part 1 (20:13)\n- CS 285: Lecture 18, Variational Inference, Part 2 (19:37)\n- CS 285: Lecture 18, Variational Inference, Part 3 (17:53)\n- CS 285: Lecture 18, Variational Inference, Part 4 (25:29)\n\n**Lecture 19: Control as Inference**\n- CS 285: Lecture 19, Control as Inference, Part 1 (21:06)\n- CS 285: Lecture 19, Control as Inference, Part 2 (28:39)\n- CS 285: Lecture 19, Control as Inference, Part 3 (21:27)\n- CS 285: Lecture 19, Control as Inference, Part 4 (09:54)\n- CS 285: Lecture 19, Control as Inference, Part 5 (10:59)\n\n**Lecture 20: Inverse Reinforcement Learning**\n- CS 285: Lecture 20, Inverse Reinforcement Learning, Part 1 (23:50)\n- CS 285: Lecture 20, Inverse Reinforcement Learning, Part 2 (12:29)\n- CS 285: Lecture 20, Inverse Reinforcement Learning, Part 3 (08:21)\n- CS 285: Lecture 20, Inverse Reinforcement Learning, Part 4 (14:22)\n\n**Guest Lectures**\n- CS 285: Eric Mitchell: Reinforcement Learning from Human Feedback (54:29)\n- CS 285: Andrea Zanette: Towards a Statistical Foundation for RL (01:00:15)\n\n**Lecture 21: RL with Sequence Models & Language Models**\n- CS 285: Lecture 21, RL with Sequence Models & Language Models, Part 1 (29:55)\n- CS 285: Lecture 21, RL with Sequence Models & Language Models, Part 2 (23:40)\n- CS 285: Lecture 21, RL with Sequence Models & Language Models, Part 3 (16:59)\n\n**Lecture 22: Transfer Learning & Meta-Learning**\n- CS 285: Lecture 22, Part 1: Transfer Learning & Meta-Learning (44:18)\n- CS 285: Lecture 22, Part 2: Transfer Learning & Meta-Learning (09:49)\n- CS 285: Lecture 22, Part 3: Transfer Learning & Meta-Learning (11:40)\n- CS 285: Lecture 22, Part 4: Transfer Learning & Meta-Learning (07:38)\n- CS 285: Lecture 22, Part 5: Transfer Learning & Meta-Learning (13:27)\n\n**Lecture 23: Challenges & Open Problems**\n- CS 285: Lecture 23, Part 1: Challenges & Open Problems (28:25)\n- CS 285: Lecture 23, Part 2: Challenges & Open Problems (38:01)\n\n**Additional Guest Lectures**\n- CS 285: Guest Lecture: Aviral Kumar (56:18)\n- CS 285: Guest Lecture: Dorsa Sadigh (01:01:41)\n\n### 4. 模仿学习基础\n- **内容**：Act、Diffusion Policy\n- **学习方式**：阅读论文\n- **关联课程**：CS285课程中会有Act讲解\n\n### 5. 大模型基础\n- **推荐课程**：CS336\n- **实践要求**：从头手搓一个大模型\n\n---\n\n## 二、VLA实战学习顺序\n\n### 第一阶段：了解VLA\n- 学习OpenVLA等早期VLA模型\n- 理解VLA的核心概念和工作原理\n\n### 第二阶段：深入研究\n- **精读pi系列所有论文与代码**：\n  - pi0\n  - pi0.5\n  - RTC\n  - 其他相关文章\n\n### 第三阶段：实践操作\n- 跑仿真环境\n- 实际操作\n- **达到要求后**：可以找实习或启动研究工作\n\n---\n\n## 三、研究方向选择\n\n### 推荐方向\n\n| 方向 | 热度 | 说明 |\n|------|------|------|\n| **Tactile + VLA** | ⭐⭐⭐⭐⭐ | 主包方向，靠此拿了很多offer |\n| **VLA + RL** | ⭐⭐⭐⭐⭐ | 企业主流方向，完美契合公司需求 |\n| **3D VLA** | ⭐⭐⭐⭐ | 许多公司在做，很有前景 |\n| **World Model** | ⭐⭐⭐ | VLA可能不可行，但WM有研究价值 |\n\n---\n\n## 四、学习时间线（参考）\n\n```\n2025.1  - 2025.5  │ 基础学习（强化学习、生成模型、大模型）\n2025.5  - 2025.9  │ 做项目 / 研究\n2025.9  - 2025.10 │ 面试\n```\n\n---\n\n## 关键要点\n\n1. ✅ **CS285必须完成作业** - 光看视频不够\n2. ✅ **MIT 6.S184强烈推荐** - 完成作业后对flow matching理解清晰很多\n3. ✅ **精读pi系列** - 这是VLA实战的核心\n4. ✅ **动手实践** - 仿真+实操缺一不可\n5. ✅ **选择热门研究方向** - Tactile+VLA 或 VLA+RL\n"
    }
  }
}